{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/BNLNLP/PPI-Relation-Extraction.git","metadata":{"execution":{"iopub.status.busy":"2023-11-16T01:08:24.184271Z","iopub.execute_input":"2023-11-16T01:08:24.184608Z","iopub.status.idle":"2023-11-16T01:08:28.927782Z","shell.execute_reply.started":"2023-11-16T01:08:24.184580Z","shell.execute_reply":"2023-11-16T01:08:28.926723Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -r /kaggle/working/PPI-Relation-Extraction/requirements.txt","metadata":{"execution":{"iopub.status.busy":"2023-11-16T01:08:32.943498Z","iopub.execute_input":"2023-11-16T01:08:32.944168Z","iopub.status.idle":"2023-11-16T01:08:35.512150Z","shell.execute_reply.started":"2023-11-16T01:08:32.944135Z","shell.execute_reply":"2023-11-16T01:08:35.510968Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.10.2 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.10.2\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"## Weights and Biases (wandb) installation and login","metadata":{}},{"cell_type":"code","source":"!pip install wandb","metadata":{"execution":{"iopub.status.busy":"2023-11-16T01:25:23.049982Z","iopub.execute_input":"2023-11-16T01:25:23.050417Z","iopub.status.idle":"2023-11-16T01:25:36.373774Z","shell.execute_reply.started":"2023-11-16T01:25:23.050386Z","shell.execute_reply":"2023-11-16T01:25:36.372591Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.15.9)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.31)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.30.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0)\nRequirement already satisfied: pathtools in /opt/conda/lib/python3.10/site-packages (from wandb) (0.1.2)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (68.0.0)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import wandb\nwandb.login()","metadata":{"execution":{"iopub.status.busy":"2023-11-16T01:27:07.446005Z","iopub.execute_input":"2023-11-16T01:27:07.446629Z","iopub.status.idle":"2023-11-16T01:27:42.722910Z","shell.execute_reply.started":"2023-11-16T01:27:07.446596Z","shell.execute_reply":"2023-11-16T01:27:42.721854Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"markdown","source":"# Running inference","metadata":{}},{"cell_type":"code","source":"%cd \"/kaggle/working/\"","metadata":{"execution":{"iopub.status.busy":"2023-11-16T01:28:10.840585Z","iopub.execute_input":"2023-11-16T01:28:10.841682Z","iopub.status.idle":"2023-11-16T01:28:10.847803Z","shell.execute_reply.started":"2023-11-16T01:28:10.841648Z","shell.execute_reply":"2023-11-16T01:28:10.846878Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}]},{"cell_type":"code","source":"!python PPI-Relation-Extraction/src/relation_extraction/run_re.py \\\n  --model_list dmis-lab/biobert-base-cased-v1.1 \\\n  --task_name \"re\" \\\n  --dataset_dir \"/kaggle/working/PPI-Relation-Extraction/datasets\" \\\n  --dataset_name \"/kaggle/working/PPI-Relation-Extraction/datasets/PPI/original/AImed\" \\\n  --output_dir \"/kaggle/working/PPI-Relation-Extraction/YOUR-OUTPUT-DIR\" \\\n  --do_train \\\n  --do_predict \\\n  --seed 1 \\\n  --remove_unused_columns False \\\n  --save_steps 100000 \\\n  --per_device_train_batch_size 16 \\\n  --per_device_eval_batch_size 32 \\\n  --num_train_epochs 10 \\\n  --optim \"adamw_torch\" \\\n  --learning_rate 5e-05 \\\n  --warmup_ratio 0.0 \\\n  --weight_decay 0.0 \\\n  --relation_representation \"EM_entity_start\" \\\n  --use_context \"attn_based\" \\\n  --overwrite_cache \\\n  --overwrite_output_dir","metadata":{"execution":{"iopub.status.busy":"2023-11-16T01:28:12.648655Z","iopub.execute_input":"2023-11-16T01:28:12.649031Z","iopub.status.idle":"2023-11-16T01:50:13.771969Z","shell.execute_reply.started":"2023-11-16T01:28:12.649000Z","shell.execute_reply":"2023-11-16T01:50:13.770971Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n[WARNING|modeling_utils.py:3645] 2023-11-16 01:28:22,814 >> Some weights of BertForRelationClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n[WARNING|modeling_utils.py:1507] 2023-11-16 01:28:22,839 >> You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 29002. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n100%|| 2/2 [00:00<00:00, 324.37it/s]\n100%|| 6/6 [00:08<00:00,  1.39s/ba]\n100%|| 1/1 [00:00<00:00,  1.04ba/s]\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myashfinul-haque\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.16.0 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.9\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20231116_012836-uyqj1lj3\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m/kaggle/working/PPI-Relation-Extraction/YOUR-OUTPUT-DIR\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: 猸锔 View project at \u001b[34m\u001b[4mhttps://wandb.ai/yashfinul-haque/huggingface\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/yashfinul-haque/huggingface/runs/uyqj1lj3\u001b[0m\n  0%|                                                  | 0/1630 [00:00<?, ?it/s][WARNING|logging.py:290] 2023-11-16 01:29:06,462 >> You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n{'loss': 0.1805, 'learning_rate': 3.4662576687116566e-05, 'epoch': 3.07}        \n{'loss': 0.0233, 'learning_rate': 1.932515337423313e-05, 'epoch': 6.13}         \n{'loss': 0.0027, 'learning_rate': 3.987730061349693e-06, 'epoch': 9.2}          \n{'train_runtime': 1288.6689, 'train_samples_per_second': 40.453, 'train_steps_per_second': 1.265, 'train_loss': 0.06347081886113055, 'epoch': 10.0}\n100%|| 1630/1630 [20:58<00:00,  1.30it/s]\n***** train metrics *****\n  epoch                    =       10.0\n  train_loss               =     0.0635\n  train_runtime            = 0:21:28.66\n  train_samples            =       5213\n  train_samples_per_second =     40.453\n  train_steps_per_second   =      1.265\n100%|| 10/10 [00:04<00:00,  2.55it/s]\nDownloading builder script: 3.19kB [00:00, 2.39MB/s]                            \u001b[A\n\nDownloading builder script: 5.83kB [00:00, 3.72MB/s]                            \u001b[A\n\nDownloading builder script: 5.76kB [00:00, 4.01MB/s]                            \u001b[A\n\nDownloading builder script: 5.27kB [00:00, 3.82MB/s]                            \u001b[A\n100%|| 10/10 [00:05<00:00,  1.75it/s]\n***** predict metrics *****\n  predict_accuracy           =     0.9082\n  predict_f1                 =     0.9082\n  predict_loss               =     0.6759\n  predict_precision          =     0.9082\n  predict_recall             =     0.9082\n  predict_runtime            = 0:00:06.11\n  predict_samples_per_second =    101.507\n  predict_steps_per_second   =      1.635\nTraceback (most recent call last):\n  File \"/kaggle/working/PPI-Relation-Extraction/src/relation_extraction/run_re.py\", line 700, in <module>\n    main()\n  File \"/kaggle/working/PPI-Relation-Extraction/src/relation_extraction/run_re.py\", line 611, in main\n    trainer.save_metrics(\"predict\", metrics, eval_info=eval_info)\nTypeError: save_metrics() got an unexpected keyword argument 'eval_info'\n","output_type":"stream"}]}]}